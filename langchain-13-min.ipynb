{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabbitmetrics/langchain-13-min/blob/main/notebooks/langchain-13-min.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "50dvxjqCFmhF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load environment variables\n",
        "\n",
        "from dotenv import load_dotenv,find_dotenv\n",
        "load_dotenv(find_dotenv())\n",
        "# load_dotenv('.env')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7RnyUOCJWmk"
      },
      "outputs": [],
      "source": [
        "# Run basic query with OpenAI wrapper\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "llm(\"explain large language models in one sentence\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "JtHgQ5XpJmgi"
      },
      "outputs": [],
      "source": [
        "# import schema for chat messages and ChatOpenAI in order to query chatmodels GPT-3.5-turbo or GPT-4\n",
        "\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "yrfYfKfdJyyF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure! Here's an example Python script that trains a simple neural network on simulated data using the Keras library:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "from keras.models import Sequential\n",
            "from keras.layers import Dense\n",
            "\n",
            "# Generate simulated data\n",
            "np.random.seed(0)\n",
            "X = np.random.rand(1000, 10)\n",
            "y = np.random.randint(2, size=(1000, 1))\n",
            "\n",
            "# Define the model\n",
            "model = Sequential()\n",
            "model.add(Dense(32, input_dim=10, activation='relu'))\n",
            "model.add(Dense(1, activation='sigmoid'))\n",
            "\n",
            "# Compile the model\n",
            "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
            "\n",
            "# Train the model\n",
            "model.fit(X, y, epochs=10, batch_size=32)\n",
            "\n",
            "# Evaluate the model\n",
            "loss, accuracy = model.evaluate(X, y)\n",
            "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
            "```\n",
            "\n",
            "In this script, we first generate simulated data using `numpy.random.rand` and `numpy.random.randint` functions. We create a neural network model using the `Sequential` class from Keras and add two dense layers. The first layer has 32 units and uses the ReLU activation function, while the second layer has 1 unit and uses the sigmoid activation function.\n",
            "\n",
            "We then compile the model using the `compile` method, specifying the loss function, optimizer, and evaluation metrics. In this case, we use binary cross-entropy as the loss function, Adam as the optimizer, and accuracy as the evaluation metric.\n",
            "\n",
            "Next, we train the model using the `fit` method, passing in the input data `X` and target labels `y`. We specify the number of epochs and batch size for training.\n",
            "\n",
            "Finally, we evaluate the trained model on the same data using the `evaluate` method and print the loss and accuracy.\n"
          ]
        }
      ],
      "source": [
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.3)\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are an expert data scientist\"),\n",
        "    HumanMessage(content=\"Write a Python script that trains a neural network on simulated data \")\n",
        "]\n",
        "response=chat(messages)\n",
        "\n",
        "print(response.content,end='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "2grf7I8AJ_hK"
      },
      "outputs": [],
      "source": [
        "# Import prompt and define PromptTemplate\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "You are an expert data scientist with an expertise in building deep learning models. \n",
        "Explain the concept of {concept} in a couple of lines\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"concept\"],\n",
        "    template=template,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "vcz7Q9Y-KFvI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nAutoencoders are a type of artificial neural network that are used to learn compact representations of data, typically for dimensionality reduction and feature extraction. They are composed of an encoder and a decoder, which work together to learn an efficient representation of the input data.'"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run LLM with PromptTemplate\n",
        "\n",
        "llm(prompt.format(concept=\"autoencoder\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "dm78i-rUKXIB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Autoencoders are a type of neural network that learn to encode data into a latent representation and then decode it back to its original form. They can be used for dimensionality reduction, data denoising, and feature learning.\n"
          ]
        }
      ],
      "source": [
        "# Import LLMChain and define chain with language model and prompt as arguments.\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "print(chain.run(\"autoencoder\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "B6MF4-nMKul3"
      },
      "outputs": [],
      "source": [
        "# Define a second prompt \n",
        "\n",
        "second_prompt = PromptTemplate(\n",
        "    input_variables=[\"ml_concept\"],\n",
        "    template=\"Turn the concept description of {ml_concept} and explain it to me like I'm five in 500 words\",\n",
        ")\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "SkJKFyk1K-MO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "An autoencoder is a type of artificial neural network that takes an input and attempts to reconstruct it at the output layer. It works by compressing the input into a hidden layer, and then reconstructing the input at the output layer by learning the weights of the model. Autoencoders are used for unsupervised learning, for feature extraction and for dimensionality reduction.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "\n",
            "An autoencoder is like a magician. It takes an input, which can be anything from a picture to a number, and it attempts to make it disappear. It does this by compressing the input into a hidden layer, shrinking it down so that it’s much smaller. Then, the autoencoder tries to make the input reappear. It uses a special kind of smartness, called learning, to figure out how to do this. To learn, the autoencoder looks at the input and the output and changes the weights of the connections between them. \n",
            "\n",
            "Autoencoders are used when you want to do something but you don’t have any instructions. This is called unsupervised learning. It’s also used to find the important parts of something, like the features of a picture, or to make something smaller, like shrinking the size of a picture. \n",
            "\n",
            "So, if you want to shrink a picture, you could ask an autoencoder to do it for you. First, the autoencoder would take the picture and compress it into a hidden layer, shrinking it down to a much smaller size. Then, it would learn how to re-create the picture\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "An autoencoder is like a magician. It takes an input, which can be anything from a picture to a number, and it attempts to make it disappear. It does this by compressing the input into a hidden layer, shrinking it down so that it’s much smaller. Then, the autoencoder tries to make the input reappear. It uses a special kind of smartness, called learning, to figure out how to do this. To learn, the autoencoder looks at the input and the output and changes the weights of the connections between them. \n",
            "\n",
            "Autoencoders are used when you want to do something but you don’t have any instructions. This is called unsupervised learning. It’s also used to find the important parts of something, like the features of a picture, or to make something smaller, like shrinking the size of a picture. \n",
            "\n",
            "So, if you want to shrink a picture, you could ask an autoencoder to do it for you. First, the autoencoder would take the picture and compress it into a hidden layer, shrinking it down to a much smaller size. Then, it would learn how to re-create the picture\n"
          ]
        }
      ],
      "source": [
        "# Define a sequential chain using the two chains above: the second chain takes the output of the first chain as input\n",
        "\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
        "\n",
        "# Run the chain specifying only the input variable for the first chain.\n",
        "explanation = overall_chain.run(\"autoencoder\")\n",
        "print(explanation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "mDDu1B_SLQls"
      },
      "outputs": [],
      "source": [
        "# Import utility for splitting up texts and split up the explanation given above into document chunks\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap  = 0,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([explanation])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "F6lfAdeuLhtp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'An autoencoder is like a magician. It takes an input, which can be anything from a picture to a'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Individual text chunks can be accessed with \"page_content\"\n",
        "\n",
        "texts[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Z5sv4e3tLw2y"
      },
      "outputs": [],
      "source": [
        "# Import and instantiate OpenAI embeddings\n",
        "\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model_name=\"ada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "dqzoir4hMlfl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.020977719222853308, 0.023827294418455335, 0.014561124470314105, 0.011903542359068018, 0.025908899139278786, 0.005840617362116563, -0.004756869854187625, -0.001205006291921359, 0.036316920880750836, 0.010448440210788053, -0.03738803499767372, -0.019350834621859294, 0.01979544989152908, 0.05626394352467466, 0.04716955602924748, -0.027566098290751746, 0.049473465590938036, 0.004511826306493519, 0.006598482986735495, -0.0002805681496021442, 0.018077619776453027, -0.019451883123455794, 0.07667578927594239, -0.016278952722744967, 0.058810369490196815, 0.02825322996425313, 0.009458163032497174, 0.031810146533675844, -0.003834799948813084, -0.04438060993460335, -0.01785531307294073, 0.02237219227017537, 0.0337300717892997, 0.020088490546158924, 0.014561124470314105, 0.020149119647116825, 0.0337907008902576, 0.021826528498909085, -0.038984605048188785, -0.014662172971910603, 0.030355042522750685, -0.027060853920124063, 0.03435657249919799, 0.02066446886790416, -0.03649880818362453, -0.0001716249864358545, -0.07315929396980346, 0.005466736974886922, -0.023786875017816737, 0.04027802959391435, 0.03486181873247087, 0.0342555239976015, 0.014945109707703396, 0.023099743344315353, 0.00835673157112755, -0.05565764878980529, 0.014278187734521313, -0.02716190242172056, -0.040116351991359954, -0.007366453461514076, 0.03094112569465557, -0.0016786723073081915, 0.005638519893262268, 0.003304293918447572, -0.057516944944471245, -0.024312329088763723, 0.039328173678907265, -0.0004171418642871354, 0.017521853017672284, -0.049998917799239824, -0.010468649911107353, 0.05784030387487042, 0.02811176206201803, -0.04413809353077175, 0.0014955214325032397, -0.01311612717219379, 0.0032613483052690603, 0.029425394445417707, 0.03015294551955769, -0.010549488712384552, 0.001841613365378519, 0.00979162308776562, 0.028212810563614528, -0.0077959109902830896, -0.01613748482050987, 0.03025399402115419, -0.019593351025690892, -0.008275892769850352, 0.028515956068404028, -0.04389557712694015, 0.05436422424407972, 0.008680087707558943, -0.034396991899836596, 0.001841613365378519, 0.019785345041369428, 0.003910586325010458, 0.019199261869464544, 0.0126513031335273, -0.024332538789083022, 0.02437295818972162, 0.0034634457741233556, -0.046401583691823706, -0.03482139933183227, -0.04882675518072044, 0.009488477582976124, 0.029445604145737006, -0.019472092823775093, -0.0019578193750451416, -0.00841736067208545, -0.0026500034736263492, 0.03278021214900223, 0.0022837017240164457, 0.009564263959173498, -0.04013656169167925, 0.04126830863485042, 0.061680154386118145, 0.012772561335443099, 0.04919052978646784, 0.007927274508019836, 0.021806318798589786, -0.0005971349443133655, -0.010630328444984348, -0.015177521261375343, 0.010640433295143997, 0.03207287263782674, 0.03310357107940141, -0.0041985754858830755, -0.016258743022425668, 0.020108700246478227, 0.005840617362116563, 0.0674197241779608, 0.0009725941561727897, -0.0169155601454481, 0.017491538467193334, 0.002788945396152184, 0.013004973820437641, -0.010953683650093143, 0.051777378877918966, 0.07315929396980346, -0.021220237489330093, 0.011600395922955926, -0.015157311561056043, -0.002680318024105299, -0.03498307693438667, -0.019209366719624196, 0.05173695947728037, -0.017350070564958235, 0.014257978034202014, 0.01799678097517583, -0.014086195581487965, 0.013298015406390083, -0.02336246944846625, 0.005860827062435863, 0.07016825087196633, 0.06616671530758346, 0.008831660459953691, -0.04385515400101117, 0.052221992284943564, 0.003112301299752927, 0.009084282645267533, 0.012853400136720297, 0.02255407957304907, -0.052141153483666366, 0.05497051897894909, -0.0467653582975711, -0.04256173318057599, -0.02352414891366584, 0.014763221473507103, 0.0007389189723619262, 0.0026348459655562255, 0.017410699665916136, 0.02085646102093751, -0.021786109098270487, -0.014641963271591304, 0.049311787988383635, 0.015248256143815487, 0.028718053071597024, -0.036903002190010525, -0.017643111219588083, 0.01676398739305335, 0.06135679918100934, 0.029607281748291404, 0.04203627724698381, 0.029627491448610703, 0.012550254631930801, 0.005941666329374359, 0.08285997247480964, 0.0012283738743308738, -0.009584473659492799, 0.010140241349596136, 0.03930796397858796, -0.04716955602924748, 0.04203627724698381, 0.022129675866343776, -0.006209445324266379, -0.0017746686166555143, 0.0070380453656641575, -0.035225593338218265, -0.04191501904506801, -0.009190383571943857, 0.04583571208288331, -0.00212202365580075, 0.015258360993975137, 0.019856078992486977, 0.013429378458465532, 0.037691180502463215, 0.02334225974814695, -0.012843295286560648, 0.004170787147944038, -0.01400535584888817, 0.014985529108341996, -0.017249020200716544, 0.011822703557790819, -0.04124809893453112, 0.0167538825428937, 0.022170095266982374, -0.014035670399367121, -0.035063915735663864, 0.03728698649607722, 0.026737498715015264, -0.04316802419015498, -0.008190000612170732, -0.017319756014479284, 0.0004515615974549361, 0.0008671245498007951, -0.007770648399222667, -0.04547193747713592, 0.0035922828464895404, -0.06256938120016733, -0.00011462717048492385, 0.0014487863840995346, -0.00678037075527049, -0.011054733083012237, 0.04874591637944324, -0.009205540847183332, -0.009594578509652448, -0.001532151630747295, 0.040116351991359954, -0.011559976522317326, -0.012934239869320092, 0.022048837065066575, -0.04003551319008276, 0.020219853598234375, 0.046442003092462304, -0.0379539103319045, -0.009412690275456154, -0.000476508004494234, -0.003081986749273977, 0.026636450213418768, 0.019886393542965928, -0.006684374678753816, -0.02344330824974345, 0.06176099318739534, -0.0380145394328624, 0.02906161983967031, -0.0036175452047193138, -0.040763062401577545, -0.02324121124655045, 0.029364765344459805, 0.022776388139206558, -0.00892260411139054, 0.021159606525727005, -0.007896959957540885, -0.04720997542988608, 0.0007067096460627178, 0.002778840545992534, -0.0168751407448095, 0.021038348323811205, 0.05678939573297646, -0.011044628232852587, 0.02443358729067952, 0.017663320919907383, 0.010913264249454543, -0.005310111797412348, -0.00995835404672244, -0.015905073266837922, 0.04805878284329667, -0.020876670721256808, -0.059740019430174984, 0.032254759940700435, -0.04102579223101882, 0.016612414640658605, -0.015632240449882182, -0.03643817908266663, 0.008604300400038973, -2.8104181809135666e-05, 0.016976189246406, -0.04830129924712827, -8.454937967201324e-05, 0.04595697028479911, 0.023059323943676754, 0.03312378077972071, -0.0032790317930484476, -0.1890015793220987, 0.0035341799580715537, -0.010418125660309105, 0.03668069548649823, 0.005926509054134884, -0.0035164964702921664, -0.003258822092729148, 0.016743777692734052, 0.04628032548990791, -0.05820407848061782, 0.0008810187769779759, 0.020421952464072562, -0.005183800704755427, -0.0050322274866993815, -0.004140472597465089, 0.03243664724357413, 0.036903002190010525, -0.006558063586096895, 0.0004291414029555507, -0.02263491837432627, 0.0031224061499125766, 0.03548831944236916, -0.027646937092028947, 0.0083668364212872, -0.05893162769211261, 0.009134806896065783, -0.00980172793792527, -0.019451883123455794, -0.037832652129988695, 0.006259970040725926, 0.059537922426981985, -0.04413809353077175, 0.025585542071524796, 0.015642345300041834, -0.045754873281606115, -0.013904307347291672, 0.021543592694438892, 0.004741712578948149, -0.03564999704492356, 0.001226479098510615, -0.0021523382062796997, -0.05537471298533509, -0.036256291779792935, -0.0008652298903958608, -0.006957206098725661, 0.002317805593305264, -0.02059373491678661, -0.002657582111246087, 0.015854549016039672, 0.006896576997767761, 0.015551401648604983, -0.011822703557790819, -0.0024327484967019302, -0.052868702695161154, -0.09878525357932166, 0.061478057382925146, 0.051251922944326796, -0.03168888833176004, 0.04231921305145401, -0.0040798430308458915, 0.002523692380969428, 0.029344555644140506, -0.009382375724977205, -0.04138956683676622, -0.0032310337547901105, 0.03257811514580923, 0.04005572289040205, 0.04805878284329667, 0.03435657249919799, 0.02801071169777634, -0.012934239869320092, 0.004804867892445961, 0.03431615309855939, 0.03322482928131721, 0.014611648721112354, -0.0812836083993235, -0.008154633636611957, -0.01866370294835791, 0.02083625132061821, -0.002116971230720925, 0.009190383571943857, -0.01977524019120978, 0.012509835231292201, -0.02443358729067952, 0.06689427196965901, -0.036943421590649124, 0.007861592050659515, 0.0009018600304322538, -0.0337907008902576, -0.01854244474644211, -0.058769950089558216, 0.02823302026393383, 0.05691065393489225, -0.0059113517788954096, 0.0027283160623636357, 0.04425935173268755, 0.013287910556230433, 0.05893162769211261, -0.007093622041542232, 0.036417969382347336, 0.018077619776453027, -0.0253430256676932, -0.012277422746297659, -0.007523079104649947, 0.02273596873856796, -0.006477224784819696, -0.031325110000722266, -0.017198495949918298, -0.03664027608585963, 0.008179895762011082, 0.022190304967301674, -0.04328928239207078, 0.02336246944846625, -0.059537922426981985, -0.034073636694727794, 0.02615141554311038, 0.004178365785563775, -0.007952536633418961, -0.017481433617033686, 0.01355063666038133, -0.029405184745098407, -0.023301840347508353, -0.028576585169361925, 0.022958275442080255, -0.05897204709275121, 0.030536931688269577, -0.04882675518072044, -0.0036023876966491905, -0.021321285990926593, -0.036801953688414026, -0.02629288344534548, 0.03094112569465557, -0.0015574137561464197, -0.030375252223069985, -0.025888689438959483, -0.0002420433210569857, -0.024898410398023416, -0.039873835587528356, -0.021927577000505585, -0.02346351795006275, 0.009134806896065783, 0.033143990480040006, -0.039045234149146686, 0.047290814231163276, 0.013975041298409221, 0.011418508620082228, -0.018481815645484213, 0.02995084851636469, 0.007396768011993026, 0.014854166056266547, -0.014500495369356206, 0.020179434197595776, 0.02829364936489173, -0.02057352521646731, 0.005118119178717703, 0.022028627364747276, -0.0005788198451913379, -0.07065328367962953, -0.003059250836414765, -0.0065277490356179455, 0.0011759547312970413, -0.014217558633563413, -0.007295719510396527, 0.056668137531060654, 0.0025401127624788593, 0.02372624591685884, -0.07853508915589873, -0.021078767724449804, 0.025565332371205497, -0.029587072047972104, -0.011297249486843835, -0.04405725472949455, 0.00890239441107124, -0.03077944809210117, -0.0760290788657248, 0.005926509054134884, 0.0043956205296575455, 0.006022505130651558, 0.05436422424407972, 0.004989281873520869, -0.011842913258110118, 0.024090020522606233, 0.036458388782985934, 0.012085429661941717, -0.020098595396318576, 0.02358477801462374, 0.03989404528784766, 0.0032007189714805123, -0.0003925112338153266, 0.003604913909189103, 0.012631093433208, -0.01314644172267274, -0.005992190580172608, -0.006886472147608112, 0.006643955278115217, 0.008235472437889158, -0.0017304597807917216, 0.01963377228897468, -0.020149119647116825, -0.02160422179539679, 0.007745386273823543, 0.003784275465184186, -0.07154251049367871, 0.014621753571272005, -0.01976513534105013, -0.017885627623419678, -0.13799216160573236, -0.010630328444984348, -0.049109690985190635, 0.024696313394830416, 0.061720573786756744, 0.029971058216683992, 0.04882675518072044, -0.022170095266982374, -0.004410777804897021, 0.01986618384264663, 0.03176972713303724, 0.033447135984829506, 0.020149119647116825, 0.05735526734191685, 0.020997928923172607, -0.008412308247005625, -0.0127523516351238, 0.010529279012065252, 0.0027611570582131467, -0.0072350904094386275, 0.012984764120118342, 0.016703358292095453, 0.005795145536398138, -0.008579038274639848, 0.017734054871024932, -0.038135797634778194, -0.03261853454644783, 0.023200791845911853, 0.009518792133455073, 0.05982085823145218, -0.018198879841014017, -0.022938065741760955, 0.02633330284598408, 0.01611727512019057, -0.01361126576133923, -0.0011001682386843426, -0.04991807899796263, 0.017390489965596834, 0.002312753168225439, -0.001496784538773196, 0.00891249926123089, 0.05113066474241099, -0.00446130205569527, -0.022331772869536772, 0.01258056918240975, -0.001481627263533721, -0.0020929722115917565, -0.026959805418527563, -0.02829364936489173, -0.024878200697704116, 0.0071390938672606565, 0.020037966295360678, -0.017228810500397245, 0.008680087707558943, -0.032194130839742534, -0.017360175415117887, 0.004842761080544648, 0.027970292297137742, -0.01969440138993258, 0.03874208864435719, 0.01982576444200803, 0.023665616815900938, -0.025545122670886197, -0.007411925752893798, -0.03993446468848626, 0.02803092139809564, 0.022978485142399554, 0.02350393921334654, 0.01399525099872852, -0.05254534749005236, 0.013803258845695172, -0.02451442609195672, -0.00017288809270581075, -0.04413809353077175, -0.011509452271519078, -0.011539766821998027, -0.01955293162505229, 0.019098213367868048, 0.0012315316400057644, 0.024211278724522032, -0.0340130075937699, -0.07146167169240152, 0.0252419771660967, -0.007553393655128897, -0.044016835328855954, -0.026798127815973165, -0.03839852373892909, -0.03728698649607722, 0.0038726931369117714, 0.014995633958501646, 0.014419655636756411, -0.04029823929423365, 0.00023841189053086151, 0.027323580024274957, 0.03583188434779726, -0.03955048038241956, 0.04312760478951638, 0.004514352519033432, -0.0007199723201049205, 0.014419655636756411, -0.0015409933746369886, 0.05779988447423182, -0.018774856300114058, -0.032194130839742534, -0.004433513717756233, -0.022998694842718857, 0.00841736067208545, -0.04813962164457387, -0.036458388782985934, -0.010549488712384552, -0.0506052125341092, -0.06826853159137139, 0.02621204464406828, 0.03944943188082306, -0.019088108517708396, 0.05161570127536457, -0.02075541251934101, -0.052626186291329556, 0.03874208864435719, -0.0032360861798699353, 0.007270457384997402, -0.06467119748395526, 0.030536931688269577, -0.050726470736025, 0.007376558311673726, -0.021200027789010794, 0.002854627155020557, 0.0032184024592598996, -0.005052437187018681, 0.08552766036753796, -0.012085429661941717, -0.04025781989359505, -0.025120718964180902, 0.04805878284329667, 0.022149885566663075, -0.0021725481394296482, 0.01597580721795547, -0.037832652129988695, -0.0032638745178089727, 0.005532418966585944, -0.007861592050659515, 0.019835869292167678, 0.02801071169777634, 0.010286762608233656, 0.028334068765530327, 0.011903542359068018, 0.02916266834126681, -0.044016835328855954, 0.020078385695999276, 0.035164964237260364, 0.0632565184616043, 0.04183418024379081, 0.024150649623564134, -0.018825380550912308, -0.015167416411215693, 0.0024921147242205222, -0.02904141013935101, -0.04300634658760058, 0.014672277822070253, 0.0018845590949723556, -0.0026777918115653866, 0.07695872508041258, -0.020896880421576107, 0.020432057314232213, 0.043531798795902375, -0.019017374566590847, 0.004797289254826224, 0.03451825010175239, 0.0013490007559423432, -0.010377706259670504, -0.03920691175170108, -0.04506773974545954, 0.02993063881604539, 0.04276383018376898, -0.005244429805713327, 0.09894693118187607, -0.030860286893378372, 0.007715071723344593, 0.015420038596529536, -0.030274203721473488, 0.026798127815973165, 0.0017910889981649454, -0.026070576741833183, 0.02736400128755875, -0.026676869614057366, 0.04611864788735351, -0.04017698109231785, 0.023807084718136036, 0.01592528296715722, -0.011661025023913826, -0.005239377380633501, 0.018774856300114058, 0.017198495949918298, 0.008897341985991415, 0.015126997010577094, -0.0377518133287115, 0.0676218211811538, 0.012550254631930801, -0.019199261869464544, -0.008452727647644225, -0.023039114243357455, 0.023968762320690434, 0.0464824224931009, -0.03554894854332706, 0.005390950598689548, 0.009498582433135774, 0.04272341078313038, -0.020341111800150174, -0.013267699924588539, 0.021442544192842392, 0.0038322737362731715, 0.03653922758426313, 0.043774315199733974, 0.045593195679051714, 0.0506052125341092, -0.03518517393757967, -0.010882949698975594, 0.005481894250126396, 0.03924733115233968, 0.012499729449809956, 0.021786109098270487, -0.03771139020278252, 0.08233452026650784, -0.03989404528784766, 0.021887157599866987, -0.01608696056971162, -0.000805232167949953, 0.029384975044779108, -0.022230724367940272, -0.00787674932589899, -0.037549712600228116, -0.032557905445489935, 0.03890376624691159, 0.0016950926888176226, -0.0028849417054995067, -0.025181348065138803, 0.00013262647848754687, -0.013378854207667282, 0.02627267374502618, -0.06596461830439046, -0.027444840088835947, -0.024575055192914617, 0.05161570127536457, 0.058810369490196815, -0.02066446886790416, -0.009776465812526145, -0.0003021989026828069, -0.04490606214290514, 0.005734516435440239, 0.008573985849560024, 0.04122788923421182, 0.05157528187472597, 0.00487560184356351, 0.0063054418664443505, 0.05658729872978346, 0.021826528498909085, -0.0015725711478012188, -0.004868023205943773, -0.028960571338073813, -0.05339415862875333, 0.042885088385684784, 0.007275509810077228, -0.005956823604613834, 0.03928775427826866, -0.0029986215026262166, -0.007573603355448197, -0.02449421639163742, 0.06442868108012367, -0.010069507398478587, -0.067904756985624, -0.00044619336670379103, 0.015561506498764635, 0.007866644475739341, 0.026656659913738067, 0.040763062401577545, 0.07279551936405607, -0.03573083584620076, 0.0013010026012686819, -0.044865642742266544, -0.003521548895371991, 0.009124702045906133, -0.016420420624980066, 0.019088108517708396, -0.017087342598162147, -0.043733895799095375, 0.039671738584335356, 0.029324345943821207, 0.020078385695999276, 0.06535832729481146, 0.017430909366235436, 0.01961356072601019, -0.020452267014551512, -0.02809155049905354, -0.013469797859104132, 0.011165886434768386, 0.008765978933915966, -0.015763603501957633, 0.027667146792348246, 0.0034306050111044934, 0.02062404946726556, 0.005370740898370248, 0.006174078348707604, -0.03839852373892909, -0.0020336059840731645, -0.05290912209579975, -0.016440630325299365, -0.026777918115653866, -0.04450186813651914, -0.030334832822431386, -0.009321746624019306, 0.041753341442513615, 0.021159606525727005, -0.05816365907997922, -0.054849260777033296, 0.013833573396174123, 0.07227005970517351, -0.007881801750978816, -0.005456632124727271, 0.05424296604216392, -0.007300771935476352, -0.03128469060008367, -0.011135571884289437, 0.03659985668522103, -0.01177217930699257, -0.01956303647521194, 0.02724274122299776, -0.04502732034482094, 0.025706800273440595, -0.019522617074573343, 0.019451883123455794, 0.003276505580508535, -0.007634232922067394, 0.010579803262863502, -0.02989021941540679, 0.00446130205569527, 0.045593195679051714, 0.02801071169777634, -0.008639667375597748, 0.009422795125615804, 0.028859520973832122, -0.00796264148357861, 0.04122788923421182, -0.005941666329374359, -0.012823085586241349, -0.010761691497059795, 0.007952536633418961, 0.0065024869102188205, 0.023988972021009733, 0.0085285140238416, -0.017188391099758647, 0.023887923519413237, 0.004327412325418611, -0.003844904798972734, -0.04478480394098934, 0.004628032548990791, -0.019128527918346995, 0.02825322996425313, 0.014732906923028153, -0.03005189701796119, -0.007593813055767496, -0.0012384787244905237, -0.016844826194330552, 0.0007679704747785818, 0.03191119503527234, 0.0008368099411141833, 0.03698384099128772, 0.006194288049026904, 0.02225093406825957, 0.02704064421980476, -0.0006498697474993627, 0.01787552277326003, 0.00588103722841646, -0.018370662293728066, 0.013227280523949938, -0.017400594815756485, 0.006745003779711716, 0.004218785186202375, -0.09256065097981582, -0.023018904543038156, -0.03583188434779726, -0.0008803872238429978, -0.12635135932065417, -0.006199340474106729, -0.06948112106111014, -0.0010275393953312103, 0.02340288884910485, 0.01881527570075266, 0.036559437284582434, -0.02647477074821918, -0.0018049832835497883, -0.01770374032054598, -0.01907800366754875, -0.035670206745242856, 0.014328711985319563, -0.010337286859031906, 0.011933856909546969, 0.03647859848330523, -0.026737498715015264, -0.003329556276677346, -0.00804348028485581, -0.004041949842747204, -0.04708871722797028, -0.0029607283145275296, -0.01854244474644211, -0.0052292725304738516, 0.03999509378944415, -0.04567403448032891, 0.03874208864435719, -0.016723567992414753, -0.005694097034801639, 0.04716955602924748, -0.021806318798589786, 0.0073108767856360024, 0.004898337756422723, -0.009084282645267533, 0.012762456485283449, -0.013975041298409221, -0.040116351991359954, -0.016531573976736214, 0.021159606525727005, -0.014712697222708853, -0.012277422746297659, 0.004112683793864753, -0.030658189890185372, 0.008316312170488952, 0.041207679533892524, -0.004082369243385804, -0.11357879146595291, -0.015369514345731286, -0.028071340798734242, 0.035569158243646364, 0.023807084718136036, 0.013469797859104132, 0.023301840347508353, -0.007204775393298381, 0.007416978177973624, 0.03257811514580923, 0.02439316789004092, 0.003059250836414765, 0.04070243330061964, -0.013500112409583081, -0.02704064421980476, -0.0012656355092945828, 0.08233452026650784, -0.01854244474644211, -0.04603780908607631, -0.027869243795541242, 0.0013073181326184629, -0.0007041834335228053, 0.04009614229104065, 0.009539001833774374, -0.03320461958099791, 0.014571229320473755, 0.0011140624076538613, -0.009048915669708758, 0.03668069548649823, -0.03005189701796119, -0.039570690082738856, 0.06960237926302594, 0.0009283853785166592, -0.01864349324803861, -0.0024719050239012225, -0.02738421098787805, 0.013469797859104132, 0.02158401209507749, -0.057759465073593225, -0.03449804040143309, 0.002778840545992534, 0.015521087098126034, 0.07125957468920852, -0.054849260777033296, 0.007169408417739606, 0.03445762100079449, -0.003574599358710153, 0.04935220738902223, -0.030395461923389287, -0.06980447626621894, 0.019179052169145245, -0.11891416725140957, 0.05266660569196816, -0.04256173318057599, 0.024534635792276018, 0.032295179341339034, 0.0013856309541863984, -0.023968762320690434, -0.02044216216439186, 0.03217392113942324, -0.034922447833428766, -0.015137101860736744, 0.03144636820263806, -0.03114322269784857, -0.004519404944113257, -0.035468109742049864, -0.0021207605495307934, -0.01221679364533976, -0.02445379699099882, -0.043774315199733974, -0.018512130195963164, -0.0005617678523392665, -0.0023253842309250016, 0.0036175452047193138, -0.020421952464072562, 0.0039080601124705456, -0.022170095266982374, 0.012378471247894159, 0.011287144636684185, -0.025646171172482697, 0.023887923519413237, -0.0001637305431447969, 0.004463828268235183, -0.021301076290607294, 0.026939595718208264, -0.0035240751079119036, -0.04292550778632338, -0.01879506600043336, -0.06337777666352008, -0.026919386017888965, 0.05278786389388396, -0.0031552471457620876, -0.053070799698354154, 0.043976415928217355, 0.017036818347363897, 0.08273871427289384, 0.010529279012065252, -0.026313093145664778]\n"
          ]
        }
      ],
      "source": [
        "# Turn the first text chunk into a vector with the embedding\n",
        "\n",
        "query_result = embeddings.embed_query(texts[0].page_content)\n",
        "print(query_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "QaOY5bIZM3Xz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "api_key:  79e8452b-1af4-4d3b-a90b-01b0f55fe9e6\n",
            "environment:  asia-southeast1-gcp-free\n"
          ]
        }
      ],
      "source": [
        "# Import and initialize Pinecone client\n",
        "\n",
        "import os\n",
        "import pinecone\n",
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=os.getenv('PINECONE_API_KEY'),\n",
        "    environment=os.getenv('PINECONE_ENV')\n",
        ")\n",
        "\n",
        "\n",
        "print(\"api_key: \", os.getenv('PINECONE_API_KEY'))\n",
        "print(\"environment: \", os.getenv('PINECONE_ENV'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pinecone Quick Start \n",
        "https://docs.pinecone.io/docs/quickstart\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "lZhSUt3FNBzN"
      },
      "outputs": [],
      "source": [
        "\n",
        "pinecone.create_index(\"quickstart\", dimension=8, metric=\"euclidean\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['quickstart']"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pinecone.list_indexes()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "index = pinecone.Index(\"quickstart\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "ename": "ForbiddenException",
          "evalue": "(403)\nReason: Forbidden\nHTTP response headers: HTTPHeaderDict({'content-length': '0', 'date': 'Fri, 30 Jun 2023 22:15:09 GMT', 'server': 'envoy'})\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mForbiddenException\u001b[0m                        Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[76], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Upsert sample data (5 8-dimensional vectors)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m index\u001b[39m.\u001b[39;49mupsert([\n\u001b[1;32m      3\u001b[0m     (\u001b[39m\"\u001b[39;49m\u001b[39mA\u001b[39;49m\u001b[39m\"\u001b[39;49m, [\u001b[39m0.1\u001b[39;49m, \u001b[39m0.1\u001b[39;49m, \u001b[39m0.1\u001b[39;49m, \u001b[39m0.1\u001b[39;49m, \u001b[39m0.1\u001b[39;49m, \u001b[39m0.1\u001b[39;49m, \u001b[39m0.1\u001b[39;49m, \u001b[39m0.1\u001b[39;49m]),\n\u001b[1;32m      4\u001b[0m     (\u001b[39m\"\u001b[39;49m\u001b[39mB\u001b[39;49m\u001b[39m\"\u001b[39;49m, [\u001b[39m0.2\u001b[39;49m, \u001b[39m0.2\u001b[39;49m, \u001b[39m0.2\u001b[39;49m, \u001b[39m0.2\u001b[39;49m, \u001b[39m0.2\u001b[39;49m, \u001b[39m0.2\u001b[39;49m, \u001b[39m0.2\u001b[39;49m, \u001b[39m0.2\u001b[39;49m]),\n\u001b[1;32m      5\u001b[0m     (\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m, [\u001b[39m0.3\u001b[39;49m, \u001b[39m0.3\u001b[39;49m, \u001b[39m0.3\u001b[39;49m, \u001b[39m0.3\u001b[39;49m, \u001b[39m0.3\u001b[39;49m, \u001b[39m0.3\u001b[39;49m, \u001b[39m0.3\u001b[39;49m, \u001b[39m0.3\u001b[39;49m]),\n\u001b[1;32m      6\u001b[0m     (\u001b[39m\"\u001b[39;49m\u001b[39mD\u001b[39;49m\u001b[39m\"\u001b[39;49m, [\u001b[39m0.4\u001b[39;49m, \u001b[39m0.4\u001b[39;49m, \u001b[39m0.4\u001b[39;49m, \u001b[39m0.4\u001b[39;49m, \u001b[39m0.4\u001b[39;49m, \u001b[39m0.4\u001b[39;49m, \u001b[39m0.4\u001b[39;49m, \u001b[39m0.4\u001b[39;49m]),\n\u001b[1;32m      7\u001b[0m     (\u001b[39m\"\u001b[39;49m\u001b[39mE\u001b[39;49m\u001b[39m\"\u001b[39;49m, [\u001b[39m0.5\u001b[39;49m, \u001b[39m0.5\u001b[39;49m, \u001b[39m0.5\u001b[39;49m, \u001b[39m0.5\u001b[39;49m, \u001b[39m0.5\u001b[39;49m, \u001b[39m0.5\u001b[39;49m, \u001b[39m0.5\u001b[39;49m, \u001b[39m0.5\u001b[39;49m])\n\u001b[1;32m      8\u001b[0m ])\n",
            "File \u001b[0;32m~/llm-projects/langchain-example/langenv/lib/python3.11/site-packages/pinecone/core/utils/error_handling.py:17\u001b[0m, in \u001b[0;36mvalidate_and_convert_errors.<locals>.inner_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m Config\u001b[39m.\u001b[39mvalidate()  \u001b[39m# raises exceptions in case of invalid config\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     18\u001b[0m \u001b[39mexcept\u001b[39;00m MaxRetryError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     19\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, ProtocolError):\n",
            "File \u001b[0;32m~/llm-projects/langchain-example/langenv/lib/python3.11/site-packages/pinecone/index.py:147\u001b[0m, in \u001b[0;36mIndex.upsert\u001b[0;34m(self, vectors, namespace, batch_size, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39masync_req is not supported when batch_size is provided.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    143\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mTo upsert in parallel, please follow: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    144\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mhttps://docs.pinecone.io/docs/insert-data#sending-upserts-in-parallel\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    146\u001b[0m \u001b[39mif\u001b[39;00m batch_size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_upsert_batch(vectors, namespace, _check_type, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    149\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(batch_size, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m batch_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    150\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mbatch_size must be a positive integer\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m~/llm-projects/langchain-example/langenv/lib/python3.11/site-packages/pinecone/index.py:231\u001b[0m, in \u001b[0;36mIndex._upsert_batch\u001b[0;34m(self, vectors, namespace, _check_type, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[39mreturn\u001b[39;00m _dict_to_vector(item)\n\u001b[1;32m    229\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid vector value passed: cannot interpret type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(item)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 231\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vector_api\u001b[39m.\u001b[39;49mupsert(\n\u001b[1;32m    232\u001b[0m     UpsertRequest(\n\u001b[1;32m    233\u001b[0m         vectors\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(_vector_transform, vectors)),\n\u001b[1;32m    234\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49margs_dict,\n\u001b[1;32m    235\u001b[0m         _check_type\u001b[39m=\u001b[39;49m_check_type,\n\u001b[1;32m    236\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m kwargs\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m k \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m _OPENAPI_ENDPOINT_PARAMS}\n\u001b[1;32m    237\u001b[0m     ),\n\u001b[1;32m    238\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m kwargs\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m k \u001b[39min\u001b[39;49;00m _OPENAPI_ENDPOINT_PARAMS}\n\u001b[1;32m    239\u001b[0m )\n",
            "File \u001b[0;32m~/llm-projects/langchain-example/langenv/lib/python3.11/site-packages/pinecone/core/client/api_client.py:776\u001b[0m, in \u001b[0;36mEndpoint.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    766\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" This method is invoked when endpoints are called\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[39m    Example:\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    774\u001b[0m \n\u001b[1;32m    775\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 776\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallable(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/llm-projects/langchain-example/langenv/lib/python3.11/site-packages/pinecone/core/client/api/vector_operations_api.py:956\u001b[0m, in \u001b[0;36mVectorOperationsApi.__init__.<locals>.__upsert\u001b[0;34m(self, upsert_request, **kwargs)\u001b[0m\n\u001b[1;32m    953\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39m_host_index\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39m_host_index\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    954\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mupsert_request\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[1;32m    955\u001b[0m     upsert_request\n\u001b[0;32m--> 956\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_with_http_info(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/llm-projects/langchain-example/langenv/lib/python3.11/site-packages/pinecone/core/client/api_client.py:838\u001b[0m, in \u001b[0;36mEndpoint.call_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    834\u001b[0m     header_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_client\u001b[39m.\u001b[39mselect_header_content_type(\n\u001b[1;32m    835\u001b[0m         content_type_headers_list)\n\u001b[1;32m    836\u001b[0m     params[\u001b[39m'\u001b[39m\u001b[39mheader\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m header_list\n\u001b[0;32m--> 838\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_client\u001b[39m.\u001b[39;49mcall_api(\n\u001b[1;32m    839\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mendpoint_path\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mhttp_method\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    840\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    841\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    842\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mheader\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    843\u001b[0m     body\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mbody\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    844\u001b[0m     post_params\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mform\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    845\u001b[0m     files\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mfile\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    846\u001b[0m     response_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mresponse_type\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    847\u001b[0m     auth_settings\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mauth\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    848\u001b[0m     async_req\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39masync_req\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    849\u001b[0m     _check_type\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_check_return_type\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    850\u001b[0m     _return_http_data_only\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_return_http_data_only\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    851\u001b[0m     _preload_content\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_preload_content\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    852\u001b[0m     _request_timeout\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_request_timeout\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    853\u001b[0m     _host\u001b[39m=\u001b[39;49m_host,\n\u001b[1;32m    854\u001b[0m     collection_formats\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mcollection_format\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
            "File \u001b[0;32m~/llm-projects/langchain-example/langenv/lib/python3.11/site-packages/pinecone/core/client/api_client.py:413\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Makes the HTTP request (synchronous) and returns deserialized data.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39mTo make an async_req request, set the async_req parameter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39m    then the method will return the response directly.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m async_req:\n\u001b[0;32m--> 413\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__call_api(resource_path, method,\n\u001b[1;32m    414\u001b[0m                            path_params, query_params, header_params,\n\u001b[1;32m    415\u001b[0m                            body, post_params, files,\n\u001b[1;32m    416\u001b[0m                            response_type, auth_settings,\n\u001b[1;32m    417\u001b[0m                            _return_http_data_only, collection_formats,\n\u001b[1;32m    418\u001b[0m                            _preload_content, _request_timeout, _host,\n\u001b[1;32m    419\u001b[0m                            _check_type)\n\u001b[1;32m    421\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mapply_async(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__call_api, (resource_path,\n\u001b[1;32m    422\u001b[0m                                                method, path_params,\n\u001b[1;32m    423\u001b[0m                                                query_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                                _request_timeout,\n\u001b[1;32m    432\u001b[0m                                                _host, _check_type))\n",
            "File \u001b[0;32m~/llm-projects/langchain-example/langenv/lib/python3.11/site-packages/pinecone/core/client/api_client.py:207\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mexcept\u001b[39;00m ApiException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    206\u001b[0m     e\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mbody\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    209\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_response \u001b[39m=\u001b[39m response_data\n\u001b[1;32m    211\u001b[0m return_data \u001b[39m=\u001b[39m response_data\n",
            "File \u001b[0;32m~/llm-projects/langchain-example/langenv/lib/python3.11/site-packages/pinecone/core/client/api_client.py:200\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    196\u001b[0m     url \u001b[39m=\u001b[39m _host \u001b[39m+\u001b[39m resource_path\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[39m# perform request and return response\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m     response_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    201\u001b[0m         method, url, query_params\u001b[39m=\u001b[39;49mquery_params, headers\u001b[39m=\u001b[39;49mheader_params,\n\u001b[1;32m    202\u001b[0m         post_params\u001b[39m=\u001b[39;49mpost_params, body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    203\u001b[0m         _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    204\u001b[0m         _request_timeout\u001b[39m=\u001b[39;49m_request_timeout)\n\u001b[1;32m    205\u001b[0m \u001b[39mexcept\u001b[39;00m ApiException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    206\u001b[0m     e\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mbody\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m~/llm-projects/langchain-example/langenv/lib/python3.11/site-packages/pinecone/core/client/api_client.py:459\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrest_client\u001b[39m.\u001b[39mOPTIONS(url,\n\u001b[1;32m    452\u001b[0m                                     query_params\u001b[39m=\u001b[39mquery_params,\n\u001b[1;32m    453\u001b[0m                                     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m                                     _request_timeout\u001b[39m=\u001b[39m_request_timeout,\n\u001b[1;32m    457\u001b[0m                                     body\u001b[39m=\u001b[39mbody)\n\u001b[1;32m    458\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPOST\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 459\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrest_client\u001b[39m.\u001b[39;49mPOST(url,\n\u001b[1;32m    460\u001b[0m                                  query_params\u001b[39m=\u001b[39;49mquery_params,\n\u001b[1;32m    461\u001b[0m                                  headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    462\u001b[0m                                  post_params\u001b[39m=\u001b[39;49mpost_params,\n\u001b[1;32m    463\u001b[0m                                  _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    464\u001b[0m                                  _request_timeout\u001b[39m=\u001b[39;49m_request_timeout,\n\u001b[1;32m    465\u001b[0m                                  body\u001b[39m=\u001b[39;49mbody)\n\u001b[1;32m    466\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPUT\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    467\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrest_client\u001b[39m.\u001b[39mPUT(url,\n\u001b[1;32m    468\u001b[0m                                 query_params\u001b[39m=\u001b[39mquery_params,\n\u001b[1;32m    469\u001b[0m                                 headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m                                 _request_timeout\u001b[39m=\u001b[39m_request_timeout,\n\u001b[1;32m    473\u001b[0m                                 body\u001b[39m=\u001b[39mbody)\n",
            "File \u001b[0;32m~/llm-projects/langchain-example/langenv/lib/python3.11/site-packages/pinecone/core/client/rest.py:271\u001b[0m, in \u001b[0;36mRESTClientObject.POST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mPOST\u001b[39m(\u001b[39mself\u001b[39m, url, headers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, query_params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, post_params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    270\u001b[0m          body\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, _preload_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, _request_timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 271\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m, url,\n\u001b[1;32m    272\u001b[0m                         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    273\u001b[0m                         query_params\u001b[39m=\u001b[39;49mquery_params,\n\u001b[1;32m    274\u001b[0m                         post_params\u001b[39m=\u001b[39;49mpost_params,\n\u001b[1;32m    275\u001b[0m                         _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    276\u001b[0m                         _request_timeout\u001b[39m=\u001b[39;49m_request_timeout,\n\u001b[1;32m    277\u001b[0m                         body\u001b[39m=\u001b[39;49mbody)\n",
            "File \u001b[0;32m~/llm-projects/langchain-example/langenv/lib/python3.11/site-packages/pinecone/core/client/rest.py:222\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[39mraise\u001b[39;00m UnauthorizedException(http_resp\u001b[39m=\u001b[39mr)\n\u001b[1;32m    221\u001b[0m \u001b[39mif\u001b[39;00m r\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m \u001b[39m403\u001b[39m:\n\u001b[0;32m--> 222\u001b[0m     \u001b[39mraise\u001b[39;00m ForbiddenException(http_resp\u001b[39m=\u001b[39mr)\n\u001b[1;32m    224\u001b[0m \u001b[39mif\u001b[39;00m r\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m \u001b[39m404\u001b[39m:\n\u001b[1;32m    225\u001b[0m     \u001b[39mraise\u001b[39;00m NotFoundException(http_resp\u001b[39m=\u001b[39mr)\n",
            "\u001b[0;31mForbiddenException\u001b[0m: (403)\nReason: Forbidden\nHTTP response headers: HTTPHeaderDict({'content-length': '0', 'date': 'Fri, 30 Jun 2023 22:15:09 GMT', 'server': 'envoy'})\n"
          ]
        }
      ],
      "source": [
        "# Upsert sample data (5 8-dimensional vectors)\n",
        "index.upsert([\n",
        "    (\"A\", [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]),\n",
        "    (\"B\", [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]),\n",
        "    (\"C\", [0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3]),\n",
        "    (\"D\", [0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4]),\n",
        "    (\"E\", [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 8,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index.describe_index_stats()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'matches': [], 'namespace': ''}"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index.query(\n",
        "  vector=[0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3],\n",
        "  top_k=3,\n",
        "  include_values=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "pinecone.delete_index(\"quickstart\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Things that Didn't work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If you are running the notebook again, delete the index first\n",
        "# pinecone.delete_index(\"langchain-quickstart\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "index_name = \"langchain-quickstart\"\n",
        "DIMENSIONS = 1024\n",
        "\n",
        "pinecone.create_index(\n",
        "        name=index_name, \n",
        "        metric=\"cosine\",\n",
        "        dimension=DIMENSIONS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload vectors to Pinecone\n",
        "search = Pinecone.from_documents(texts, embeddings, index_name=index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "cCXVuXwPNKcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(page_content='An autoencoder is like a magician. It takes an input, which can be anything from a picture to a', metadata={}), Document(page_content='learn, the autoencoder looks at the input and the output and changes the weights of the connections', metadata={}), Document(page_content='So, if you want to shrink a picture, you could ask an autoencoder to do it for you. First, the', metadata={}), Document(page_content='Autoencoders are used when you want to do something but you don’t have any instructions. This is', metadata={})]\n"
          ]
        }
      ],
      "source": [
        "# Do a simple vector similarity search\n",
        "\n",
        "query = \"What is magical about an autoencoder?\"\n",
        "result = search.similarity_search(query)\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "4Ogz8luZNRnJ"
      },
      "outputs": [],
      "source": [
        "# Import Python REPL tool and instantiate Python agent\n",
        "\n",
        "from langchain.agents.agent_toolkits import create_python_agent\n",
        "from langchain.tools.python.tool import PythonREPLTool\n",
        "from langchain.python import PythonREPL\n",
        "from langchain.llms.openai import OpenAI\n",
        "\n",
        "agent_executor = create_python_agent(\n",
        "    llm=OpenAI(temperature=0, max_tokens=1000),\n",
        "    tool=PythonREPLTool(),\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "BVHMDj0sNi09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to solve a quadratic equation\n",
            "Action: Python REPL\n",
            "Action Input: import numpy as np\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I can use the numpy function to solve the equation\n",
            "Action: Python REPL\n",
            "Action Input: np.roots([3,2,-1])\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: (-1.0, 0.3333333333333333)\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'(-1.0, 0.3333333333333333)'"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Execute the Python agent\n",
        "\n",
        "agent_executor.run(\"Find the roots (zeros) if the quadratic function 3 * x**2 + 2*x -1\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyONM96f7/m0jUCD9c87+MQy",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
